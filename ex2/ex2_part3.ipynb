{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f75e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized with optimized configuration\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, StopWordsRemover, CountVectorizer,\n",
    "    IDF, ChiSqSelector, Normalizer, StringIndexer\n",
    ")\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit # Changed from CrossValidator\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # For results summary, keep pandas import\n",
    "import random\n",
    "import os # For checking file existence\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize SparkSession with optimized configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DIC EX 2_2 - group 36 - TVS with Custom Vocab\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"200\") \\\n",
    "    .config(\"spark.rdd.compress\", \"true\") \\\n",
    "    .config(\"spark.logLevel\", \"ERROR\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark session initialized with optimized configuration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd740d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading review data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Schema:\n",
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          reviewText|            category|\n",
      "+--------------------+--------------------+\n",
      "|This was a gift f...|Patio_Lawn_and_Garde|\n",
      "|This is a very ni...|Patio_Lawn_and_Garde|\n",
      "|The metal base wi...|Patio_Lawn_and_Garde|\n",
      "|For the most part...|Patio_Lawn_and_Garde|\n",
      "|This hose is supp...|Patio_Lawn_and_Garde|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 78829\n",
      "Category distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>    (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|category                  |count|\n",
      "+--------------------------+-----+\n",
      "|Book                      |22507|\n",
      "|Electronic                |7825 |\n",
      "|Clothing_Shoes_and_Jewelry|5749 |\n",
      "|Movies_and_TV             |4607 |\n",
      "|Home_and_Kitche           |4254 |\n",
      "|CDs_and_Vinyl             |3749 |\n",
      "|Cell_Phones_and_Accessorie|3447 |\n",
      "|Sports_and_Outdoor        |3269 |\n",
      "|Kindle_Store              |3205 |\n",
      "|Health_and_Personal_Care  |2982 |\n",
      "|Apps_for_Android          |2638 |\n",
      "|Toys_and_Game             |2253 |\n",
      "|Beauty                    |2023 |\n",
      "|Tools_and_Home_Improvement|1926 |\n",
      "|Automotive                |1374 |\n",
      "|Grocery_and_Gourmet_Food  |1297 |\n",
      "|Office_Product            |1243 |\n",
      "|Pet_Supplie               |1235 |\n",
      "|Patio_Lawn_and_Garde      |994  |\n",
      "|Baby                      |916  |\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the development dataset\n",
    "print(\"Loading review data...\")\n",
    "data_path = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\" # Ensure this path is correct\n",
    "df = spark.read.json(data_path)\n",
    "\n",
    "# Cache the DataFrame to improve performance of multiple operations\n",
    "df = df.cache()\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"Dataset Schema:\")\n",
    "df.printSchema()\n",
    "print(\"\\nSample data:\")\n",
    "df.select(\"reviewText\", \"category\").show(5, truncate=True)\n",
    "\n",
    "# Function to check dataset statistics\n",
    "def print_stats(df_to_stat):\n",
    "    total_reviews = df_to_stat.count()\n",
    "    category_counts_df = df_to_stat.groupBy(\"category\").count().orderBy(\"count\", ascending=False)\n",
    "    \n",
    "    print(f\"Total number of reviews: {total_reviews}\")\n",
    "    print(\"Category distribution:\")\n",
    "    category_counts_df.show(20, truncate=False)\n",
    "    \n",
    "    return category_counts_df\n",
    "\n",
    "# Get dataset statistics\n",
    "category_counts = print_stats(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "408639b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training, validation, and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (for TrainValidationSplit input): 55332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size (for intermediate model check): 11805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size (for final model evaluation): 11692\n",
      "Loading selected features from output_ds.txt to use as vocabulary...\n",
      "Loaded 75 features from output_ds.txt to be used as vocabulary.\n",
      "Sample vocabulary features: ['amazon', 'author', 'back', 'bad', 'big', 'bit', 'bought', 'buy', 'character', 'characters']\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation: Split into training, validation, and test sets\n",
    "print(\"Splitting data into training, validation, and test sets...\")\n",
    "# train_data for TrainValidationSplit, validation_data for intermediate check, test_data for final evaluation\n",
    "train_data, temp_data = df.randomSplit([0.7, 0.3], seed=seed)\n",
    "validation_data, test_data = temp_data.randomSplit([0.5, 0.5], seed=seed)\n",
    "\n",
    "# Cache the data splits\n",
    "train_data = train_data.cache()\n",
    "validation_data = validation_data.cache()\n",
    "test_data = test_data.cache()\n",
    "\n",
    "print(f\"Training set size (for TrainValidationSplit input): {train_data.count()}\")\n",
    "print(f\"Validation set size (for intermediate model check): {validation_data.count()}\")\n",
    "print(f\"Test set size (for final model evaluation): {test_data.count()}\")\n",
    "\n",
    "# Load the top features selected in Part 2 (to be used as vocabulary)\n",
    "print(\"Loading selected features from output_ds.txt to use as vocabulary...\")\n",
    "selected_vocabulary_path = \"output_ds.txt\"\n",
    "if not os.path.exists(selected_vocabulary_path):\n",
    "    print(f\"ERROR: {selected_vocabulary_path} not found. Please ensure it's in the correct location.\")\n",
    "    spark.stop()\n",
    "    exit()\n",
    "\n",
    "with open(selected_vocabulary_path, \"r\") as f:\n",
    "    selected_vocabulary = f.read().strip().split()\n",
    "\n",
    "# Broadcast the selected vocabulary\n",
    "broadcast_vocabulary = spark.sparkContext.broadcast(selected_vocabulary)\n",
    "\n",
    "print(f\"Loaded {len(selected_vocabulary)} features from output_ds.txt to be used as vocabulary.\")\n",
    "if selected_vocabulary:\n",
    "    print(f\"Sample vocabulary features: {selected_vocabulary[:10]}\")\n",
    "else:\n",
    "    print(\"Warning: Loaded vocabulary is empty!\")\n",
    "\n",
    "\n",
    "# Efficiently load stopwords once and broadcast them\n",
    "def load_stopwords(path: str) -> list[str]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"ERROR: Stopwords file {path} not found.\")\n",
    "        return [] # Return empty list to avoid error, but flag it\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(line.strip() for line in f if line.strip())\n",
    "    return list(stopwords)\n",
    "\n",
    "# Load stopwords once\n",
    "stopwords_list = load_stopwords(\"stopwords.txt\")\n",
    "if not stopwords_list:\n",
    "    print(\"Warning: Stopwords list is empty. Proceeding without stopword removal if file was not found.\")\n",
    "# Broadcast stopwords to all executors\n",
    "broadcast_stopwords = spark.sparkContext.broadcast(stopwords_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac13dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "spark.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2141fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the ML Pipeline for classification...\n",
      "WARNING: Vocabulary size (75) is less than 2000. ChiSqSelector_2000 will select all 75 features.\n"
     ]
    }
   ],
   "source": [
    "print(\"Building the ML Pipeline for classification...\")\n",
    "\n",
    "# 1. Convert category to numeric labels\n",
    "label_indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "\n",
    "# 2. Text preprocessing with optimized tokenizer\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"reviewText\", \n",
    "    outputCol=\"tokens\", \n",
    "    pattern=\"[\\\\s\\\\t\\\\d\\\\(\\\\)\\\\[\\\\]\\\\{\\\\}\\\\.\\\\!\\\\?\\\\,\\\\;\\\\:\\\\+\\\\=\\\\-\\\\_\\\\\\\"\\\\'`\\\\~\\\\#\\\\@\\\\&\\\\*\\\\%\\\\€\\\\$\\\\§\\\\\\\\\\\\/]+\"\n",
    ")\n",
    "\n",
    "# 3. Remove stopwords using broadcast variable\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"tokens\", \n",
    "    outputCol=\"tokens_filtered\", \n",
    "    stopWords=broadcast_stopwords.value if broadcast_stopwords.value else [] # Handle empty stopwords\n",
    ")\n",
    "\n",
    "# 4. Create term frequency vectors using the pre-defined vocabulary\n",
    "count_vectorizer = CountVectorizerModel.from_vocabulary(\n",
    "    vocabulary=broadcast_vocabulary.value,\n",
    "    inputCol=\"tokens_filtered\",\n",
    "    outputCol=\"tf\"\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Calculate IDF\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tf_idf\")\n",
    "\n",
    "# Determine number of features for ChiSqSelector safely based on vocabulary size\n",
    "num_vocab_features = len(selected_vocabulary) if selected_vocabulary else 0\n",
    "\n",
    "# 6. Feature selection using Chi-Square - reduced dimensionality\n",
    "# Ensure numTopFeatures is not greater than the actual number of features from CountVectorizer (vocab size)\n",
    "chi_sq_selector_2000 = ChiSqSelector(\n",
    "    numTopFeatures=min(2000, num_vocab_features) if num_vocab_features > 0 else 100, # Fallback if vocab is tiny/empty\n",
    "    featuresCol=\"tf_idf\", \n",
    "    outputCol=\"selected_features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "chi_sq_selector_500 = ChiSqSelector(\n",
    "    numTopFeatures=min(500, num_vocab_features) if num_vocab_features > 0 else 50, # Fallback\n",
    "    featuresCol=\"tf_idf\", \n",
    "    outputCol=\"selected_features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "if num_vocab_features == 0:\n",
    "    print(\"WARNING: Vocabulary size is 0. ChiSqSelector numTopFeatures is set to a small default.\")\n",
    "elif num_vocab_features < 2000:\n",
    "    print(f\"WARNING: Vocabulary size ({num_vocab_features}) is less than 2000. ChiSqSelector_2000 will select all {num_vocab_features} features.\")\n",
    "elif num_vocab_features < 500:\n",
    "    print(f\"WARNING: Vocabulary size ({num_vocab_features}) is less than 500. ChiSqSelectors will select all {num_vocab_features} features.\")\n",
    "\n",
    "\n",
    "# 7. Vector normalization\n",
    "normalizer = Normalizer(inputCol=\"selected_features\", outputCol=\"normalized_features\", p=2.0)\n",
    "\n",
    "# 8. Create SVM classifier\n",
    "svm = LinearSVC(featuresCol=\"normalized_features\", labelCol=\"label\")\n",
    "\n",
    "# Wrap in OneVsRest for multi-class classification\n",
    "ovr = OneVsRest(classifier=svm, featuresCol=\"normalized_features\", labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Build the pipeline with 2000 features (or fewer if vocab is smaller)\n",
    "pipeline_2000 = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    stopwords_remover,\n",
    "    count_vectorizer, # Uses custom vocabulary\n",
    "    idf,\n",
    "    chi_sq_selector_2000,\n",
    "    normalizer,\n",
    "    ovr\n",
    "])\n",
    "\n",
    "# Build the pipeline with 500 features (or fewer if vocab is smaller)\n",
    "pipeline_500 = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    stopwords_remover,\n",
    "    count_vectorizer, # Uses custom vocabulary\n",
    "    idf,\n",
    "    chi_sq_selector_500,\n",
    "    normalizer,\n",
    "    ovr\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad733532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up parameter grid for SVM optimization...\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM parameter grid\n",
    "print(\"Setting up parameter grid for SVM optimization...\")\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(svm.maxIter, [10, 50]) \\\n",
    "    .build()\n",
    "\n",
    "# Create an evaluator for model assessment\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Create TrainValidationSplitters\n",
    "# It will split the 'train_data' internally using trainRatio for its own training and validation.\n",
    "tvs_2000 = TrainValidationSplit(\n",
    "    estimator=pipeline_2000,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator_f1,\n",
    "    trainRatio=0.8,  # 80% of train_data for TVS's internal training, 20% for its internal validation\n",
    "    parallelism=4,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "tvs_500 = TrainValidationSplit(\n",
    "    estimator=pipeline_500,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator_f1,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Results container\n",
    "results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bac63193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with ChiSqSelector for up to 75 features...\n",
      "This may take some time (but faster than CrossValidator)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.                                                    4]\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Train model with \"2000\" features ---\n",
    "print(f\"\\nTraining model with ChiSqSelector for up to {chi_sq_selector_2000.getNumTopFeatures()} features...\")\n",
    "print(\"This may take some time (but faster than CrossValidator)...\")\n",
    "tvs_model_2000 = tvs_2000.fit(train_data) # Fit on the 70% training split\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_pipeline_model_2000 = tvs_model_2000.bestModel\n",
    "\n",
    "best_params_map_2000 = tvs_model_2000.getEstimatorParamMaps()[np.argmax(tvs_model_2000.validationMetrics)]\n",
    "params_2000 = {\n",
    "    \"regParam\": best_params_map_2000[svm.regParam],\n",
    "    \"standardization\": best_params_map_2000[svm.standardization],\n",
    "    \"maxIter\": best_params_map_2000[svm.maxIter]\n",
    "}\n",
    "\n",
    "# Evaluate on the explicit VALIDATION set\n",
    "print(f\"\\nEvaluating model (up to {chi_sq_selector_2000.getNumTopFeatures()} features) on the VALIDATION set...\")\n",
    "predictions_validation_2000 = best_pipeline_model_2000.transform(validation_data).cache()\n",
    "f1_score_validation_2000 = evaluator_f1.evaluate(predictions_validation_2000)\n",
    "print(f\"F1 score on VALIDATION set: {f1_score_validation_2000:.4f}\")\n",
    "\n",
    "# Evaluate on the TEST set\n",
    "print(f\"Evaluating model (up to {chi_sq_selector_2000.getNumTopFeatures()} features) on the TEST set...\")\n",
    "predictions_test_2000 = best_pipeline_model_2000.transform(test_data).cache()\n",
    "f1_score_test_2000 = evaluator_f1.evaluate(predictions_test_2000)\n",
    "\n",
    "results.append({\n",
    "    \"feature_set\": f\"{chi_sq_selector_2000.getNumTopFeatures()} features (max)\",\n",
    "    \"regParam\": params_2000[\"regParam\"],\n",
    "    \"standardization\": params_2000[\"standardization\"],\n",
    "    \"maxIter\": params_2000[\"maxIter\"],\n",
    "    \"f1_score_validation\": f1_score_validation_2000,\n",
    "    \"f1_score_test\": f1_score_test_2000,\n",
    "    \"predictions_on_test_set\": predictions_test_2000 # Keep for later best model selection\n",
    "})\n",
    "\n",
    "print(f\"\\nBest parameters for model with up to {chi_sq_selector_2000.getNumTopFeatures()} features:\")\n",
    "print(f\"  regParam: {params_2000['regParam']}\")\n",
    "print(f\"  standardization: {params_2000['standardization']}\")\n",
    "print(f\"  maxIter: {params_2000['maxIter']}\")\n",
    "print(f\"  F1 score on VALIDATION set: {f1_score_validation_2000:.4f}\")\n",
    "print(f\"  F1 score on TEST set: {f1_score_test_2000:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model with \"500\" features ---\n",
    "print(f\"\\nTraining model with ChiSqSelector for up to {chi_sq_selector_500.getNumTopFeatures()} features...\")\n",
    "print(\"This may take some time...\")\n",
    "tvs_model_500 = tvs_500.fit(train_data) # Fit on the 70% training split\n",
    "\n",
    "best_pipeline_model_500 = tvs_model_500.bestModel\n",
    "\n",
    "best_params_map_500 = tvs_model_500.getEstimatorParamMaps()[np.argmax(tvs_model_500.validationMetrics)]\n",
    "params_500 = {\n",
    "    \"regParam\": best_params_map_500[svm.regParam],\n",
    "    \"standardization\": best_params_map_500[svm.standardization],\n",
    "    \"maxIter\": best_params_map_500[svm.maxIter]\n",
    "}\n",
    "\n",
    "# Evaluate on the explicit VALIDATION set\n",
    "print(f\"\\nEvaluating model (up to {chi_sq_selector_500.getNumTopFeatures()} features) on the VALIDATION set...\")\n",
    "predictions_validation_500 = best_pipeline_model_500.transform(validation_data).cache()\n",
    "f1_score_validation_500 = evaluator_f1.evaluate(predictions_validation_500)\n",
    "print(f\"F1 score on VALIDATION set: {f1_score_validation_500:.4f}\")\n",
    "\n",
    "# Evaluate on the TEST set\n",
    "print(f\"Evaluating model (up to {chi_sq_selector_500.getNumTopFeatures()} features) on the TEST set...\")\n",
    "predictions_test_500 = best_pipeline_model_500.transform(test_data).cache()\n",
    "f1_score_test_500 = evaluator_f1.evaluate(predictions_test_500)\n",
    "\n",
    "results.append({\n",
    "    \"feature_set\": f\"{chi_sq_selector_500.getNumTopFeatures()} features (max)\",\n",
    "    \"regParam\": params_500[\"regParam\"],\n",
    "    \"standardization\": params_500[\"standardization\"],\n",
    "    \"maxIter\": params_500[\"maxIter\"],\n",
    "    \"f1_score_validation\": f1_score_validation_500,\n",
    "    \"f1_score_test\": f1_score_test_500,\n",
    "    \"predictions_on_test_set\": predictions_test_500 # Keep for later best model selection\n",
    "})\n",
    "\n",
    "print(f\"\\nBest parameters for model with up to {chi_sq_selector_500.getNumTopFeatures()} features:\")\n",
    "print(f\"  regParam: {params_500['regParam']}\")\n",
    "print(f\"  standardization: {params_500['standardization']}\")\n",
    "print(f\"  maxIter: {params_500['maxIter']}\")\n",
    "print(f\"  F1 score on VALIDATION set: {f1_score_validation_500:.4f}\")\n",
    "print(f\"  F1 score on TEST set: {f1_score_test_500:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bca5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which model performed better based on F1 score on the TEST set\n",
    "best_result_config = max(results, key=lambda x: x['f1_score_test'])\n",
    "best_predictions_df = best_result_config[\"predictions_on_test_set\"]\n",
    "\n",
    "print(\"\\nBest Overall Configuration (based on Test Set F1 Score):\")\n",
    "print(f\"Feature Set: {best_result_config['feature_set']}\")\n",
    "print(f\"regParam: {best_result_config['regParam']}\")\n",
    "print(f\"standardization: {best_result_config['standardization']}\")\n",
    "print(f\"maxIter: {best_result_config['maxIter']}\")\n",
    "print(f\"F1 Score on Validation Set: {best_result_config['f1_score_validation']:.4f}\")\n",
    "print(f\"F1 Score on Test Set: {best_result_config['f1_score_test']:.4f}\")\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(\"best_model_params_tvs.txt\", \"w\") as f:\n",
    "    f.write(f\"Best Model (based on Test Set F1 from TrainValidationSplit)\\n\")\n",
    "    f.write(f\"Feature Set: {best_result_config['feature_set']}\\n\")\n",
    "    f.write(f\"regParam: {best_result_config['regParam']}\\n\")\n",
    "    f.write(f\"standardization: {best_result_config['standardization']}\\n\")\n",
    "    f.write(f\"maxIter: {best_result_config['maxIter']}\\n\")\n",
    "    f.write(f\"F1 Score on Validation Set: {best_result_config['f1_score_validation']:.4f}\\n\")\n",
    "    f.write(f\"F1 Score on Test Set: {best_result_config['f1_score_test']:.4f}\\n\")\n",
    "\n",
    "print(\"\\nBest model parameters saved to 'best_model_params_tvs.txt'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec614fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Confusion Matrix for the best model on the test set ---\n",
    "# Fit the label_indexer on the original data to get all labels for consistent mapping\n",
    "label_mapping_model = label_indexer.fit(df) # Fit on full df to get all labels\n",
    "idx_to_label_udf = udf(lambda idx: label_mapping_model.labels[int(idx)], StringType()) # StringType might be needed\n",
    "\n",
    "# Get category mapping\n",
    "# Using the already fitted label_indexer_model from the pipeline training is generally fine\n",
    "# but fitting on full 'df' ensures all categories are known if 'train_data' was sparse.\n",
    "# Here, best_pipeline_model_2000 or best_pipeline_model_500 contains a fitted label_indexer.\n",
    "# Let's use the one from the overall best model's pipeline.\n",
    "# We need the pipeline that generated 'best_predictions_df'.\n",
    "if best_result_config[\"feature_set\"] == f\"{chi_sq_selector_2000.getNumTopFeatures()} features (max)\":\n",
    "    final_best_pipeline_model = best_pipeline_model_2000\n",
    "else:\n",
    "    final_best_pipeline_model = best_pipeline_model_500\n",
    "\n",
    "label_indexer_in_best_model = final_best_pipeline_model.stages[0] # First stage is label_indexer\n",
    "category_labels_ordered = label_indexer_in_best_model.labels\n",
    "\n",
    "# Convert predictions to a pandas DataFrame - limit columns to only what's needed\n",
    "# Best_predictions_df already has 'category', 'label' (numeric true), 'prediction' (numeric)\n",
    "pred_pd_df = best_predictions_df.select(\"label\", \"prediction\").limit(20000).toPandas() # Limit for safety\n",
    "true_labels_pd = pred_pd_df[\"label\"].astype(int)\n",
    "pred_labels_pd = pred_pd_df[\"prediction\"].astype(int)\n",
    "\n",
    "# Get top categories for confusion matrix display (can be all if not too many)\n",
    "top_n_categories_for_cm = 10 # or len(category_labels_ordered)\n",
    "category_counts_pd = category_counts.limit(top_n_categories_for_cm).toPandas()\n",
    "top_categories_list = category_counts_pd['category'].tolist()\n",
    "\n",
    "# Map top category names to their numerical indices used in the model\n",
    "# The 'label_indexer_in_best_model.labels' gives index -> label_string. We need label_string -> index.\n",
    "string_to_idx_map = {label: float(idx) for idx, label in enumerate(category_labels_ordered)}\n",
    "top_indices = [string_to_idx_map[cat] for cat in top_categories_list if cat in string_to_idx_map]\n",
    "\n",
    "\n",
    "if top_indices:\n",
    "    conf_matrix = np.zeros((len(top_indices), len(top_indices)), dtype=int)\n",
    "    # Fill confusion matrix efficiently\n",
    "    for i, true_cat_idx_numeric in enumerate(top_indices):\n",
    "        for j, pred_cat_idx_numeric in enumerate(top_indices):\n",
    "            conf_matrix[i, j] = sum((true_labels_pd == true_cat_idx_numeric) & (pred_labels_pd == pred_cat_idx_numeric))\n",
    "    \n",
    "    conf_matrix_pd = pd.DataFrame(conf_matrix, index=top_categories_list[:len(top_indices)], columns=top_categories_list[:len(top_indices)])\n",
    "    print(\"\\nConfusion Matrix for Best Model on Test Set (Top Categories):\")\n",
    "    print(conf_matrix_pd)\n",
    "else:\n",
    "    print(\"\\nCould not generate confusion matrix: No top categories found or mapping issue.\")\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"We have successfully implemented an optimized text classification pipeline using Spark ML.\")\n",
    "print(\"Key changes: Used a pre-defined vocabulary with CountVectorizer and TrainValidationSplit for hyperparameter tuning.\")\n",
    "print(\"The pipeline includes text preprocessing, feature extraction with TF-IDF, and SVM classification.\")\n",
    "print(f\"The best model (based on Test F1) used '{best_result_config['feature_set']}' and achieved an F1 score of {best_result_config['f1_score_test']:.4f} on the test set.\")\n",
    "print(f\"This model also scored {best_result_config['f1_score_validation']:.4f} on the separate validation set.\")\n",
    "\n",
    "# Clean up and release resources\n",
    "train_data.unpersist()\n",
    "validation_data.unpersist()\n",
    "test_data.unpersist()\n",
    "\n",
    "# Unpersist prediction DataFrames if they were cached (they were)\n",
    "if 'predictions_validation_2000' in locals() and predictions_validation_2000.is_cached: predictions_validation_2000.unpersist()\n",
    "if 'predictions_test_2000' in locals() and predictions_test_2000.is_cached: predictions_test_2000.unpersist()\n",
    "if 'predictions_validation_500' in locals() and predictions_validation_500.is_cached: predictions_validation_500.unpersist()\n",
    "if 'predictions_test_500' in locals() and predictions_test_500.is_cached: predictions_test_500.unpersist()\n",
    "\n",
    "df.unpersist()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"\\nSpark session stopped and resources released\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
