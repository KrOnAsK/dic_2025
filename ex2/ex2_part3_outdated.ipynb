{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad380673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized with optimized configuration\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, ChiSqSelector, Normalizer, StringIndexer\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize SparkSession with optimized configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DIC EX 2_2 - group 36\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"200\") \\\n",
    "    .config(\"spark.rdd.compress\", \"true\") \\\n",
    "    .config(\"spark.logLevel\", \"ERROR\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark session initialized with optimized configuration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dcbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading review data...\n",
      "Dataset Schema:\n",
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n",
      "\n",
      "Sample data:\n",
      "+--------------------+--------------------+\n",
      "|          reviewText|            category|\n",
      "+--------------------+--------------------+\n",
      "|This was a gift f...|Patio_Lawn_and_Garde|\n",
      "|This is a very ni...|Patio_Lawn_and_Garde|\n",
      "|The metal base wi...|Patio_Lawn_and_Garde|\n",
      "|For the most part...|Patio_Lawn_and_Garde|\n",
      "|This hose is supp...|Patio_Lawn_and_Garde|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 78829\n",
      "Category distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|category                  |count|\n",
      "+--------------------------+-----+\n",
      "|Book                      |22507|\n",
      "|Electronic                |7825 |\n",
      "|Clothing_Shoes_and_Jewelry|5749 |\n",
      "|Movies_and_TV             |4607 |\n",
      "|Home_and_Kitche           |4254 |\n",
      "|CDs_and_Vinyl             |3749 |\n",
      "|Cell_Phones_and_Accessorie|3447 |\n",
      "|Sports_and_Outdoor        |3269 |\n",
      "|Kindle_Store              |3205 |\n",
      "|Health_and_Personal_Care  |2982 |\n",
      "|Apps_for_Android          |2638 |\n",
      "|Toys_and_Game             |2253 |\n",
      "|Beauty                    |2023 |\n",
      "|Tools_and_Home_Improvement|1926 |\n",
      "|Automotive                |1374 |\n",
      "|Grocery_and_Gourmet_Food  |1297 |\n",
      "|Office_Product            |1243 |\n",
      "|Pet_Supplie               |1235 |\n",
      "|Patio_Lawn_and_Garde      |994  |\n",
      "|Baby                      |916  |\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training, validation, and test sets...\n",
      "Training set size: 55332\n",
      "Validation set size: 11805\n",
      "Test set size: 11692\n",
      "Loading selected features from output_ds.txt...\n",
      "Loaded 75 features from output_ds.txt\n",
      "Sample features: ['amazon', 'author', 'back', 'bad', 'big', 'bit', 'bought', 'buy', 'character', 'characters']\n",
      "Building the ML Pipeline for classification...\n",
      "Setting up parameter grid for SVM optimization...\n",
      "\n",
      "Training model with 2000 features...\n",
      "This may take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11924:(11 + 1) / 14][Stage 11926:(5 + 0) / 14][Stage 11928:(5 + 0) / 14] ]]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 203\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model with 2000 features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis may take some time...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m cv_model_2000 \u001b[38;5;241m=\u001b[39m \u001b[43mcv_2000\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m    206\u001b[0m best_model_2000 \u001b[38;5;241m=\u001b[39m cv_model_2000\u001b[38;5;241m.\u001b[39mbestModel\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/tuning.py:847\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    841\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    843\u001b[0m tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    844\u001b[0m     inheritable_thread_target,\n\u001b[1;32m    845\u001b[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[1;32m    846\u001b[0m )\n\u001b[0;32m--> 847\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    848\u001b[0m     metrics_all[i][j] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the development dataset\n",
    "print(\"Loading review data...\")\n",
    "data_path = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "df = spark.read.json(data_path)\n",
    "\n",
    "# Cache the DataFrame to improve performance of multiple operations\n",
    "df = df.cache()\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"Dataset Schema:\")\n",
    "df.printSchema()\n",
    "print(\"\\nSample data:\")\n",
    "df.select(\"reviewText\", \"category\").show(5, truncate=True)\n",
    "\n",
    "# Function to check dataset statistics\n",
    "def print_stats(df):\n",
    "    total_reviews = df.count()\n",
    "    category_counts = df.groupBy(\"category\").count().orderBy(\"count\", ascending=False)\n",
    "    \n",
    "    print(f\"Total number of reviews: {total_reviews}\")\n",
    "    print(\"Category distribution:\")\n",
    "    category_counts.show(20, truncate=False)\n",
    "    \n",
    "    return category_counts\n",
    "\n",
    "# Get dataset statistics\n",
    "category_counts = print_stats(df)\n",
    "\n",
    "# Convert category_counts to Pandas for visualization but limit conversion size\n",
    "category_dist = category_counts.limit(10).toPandas()\n",
    "\n",
    "# Data Preparation: Split into training, validation, and test sets\n",
    "print(\"Splitting data into training, validation, and test sets...\")\n",
    "train_data, temp_data = df.randomSplit([0.7, 0.3], seed=seed)\n",
    "validation_data, test_data = temp_data.randomSplit([0.5, 0.5], seed=seed)\n",
    "\n",
    "# Cache the training data since we'll use it multiple times\n",
    "train_data = train_data.cache()\n",
    "validation_data = validation_data.cache()\n",
    "test_data = test_data.cache()\n",
    "\n",
    "print(f\"Training set size: {train_data.count()}\")\n",
    "print(f\"Validation set size: {validation_data.count()}\")\n",
    "print(f\"Test set size: {test_data.count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the top features selected in Part 2\n",
    "print(\"Loading selected features from output_ds.txt...\")\n",
    "# Broadcast the selected features to reduce serialization overhead\n",
    "with open(\"output_ds.txt\", \"r\") as f:\n",
    "    selected_features = f.read().strip().split()\n",
    "\n",
    "# Broadcast the selected features\n",
    "broadcast_features = spark.sparkContext.broadcast(selected_features)\n",
    "\n",
    "print(f\"Loaded {len(selected_features)} features from output_ds.txt\")\n",
    "print(f\"Sample features: {selected_features[:10]}\")\n",
    "\n",
    "# Efficiently load stopwords once and broadcast them\n",
    "def load_stopwords(path: str) -> list[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(line.strip() for line in f if line.strip())\n",
    "    return list(stopwords)\n",
    "\n",
    "# Load stopwords once\n",
    "stopwords_list = load_stopwords(\"stopwords.txt\")\n",
    "# Broadcast stopwords to all executors\n",
    "broadcast_stopwords = spark.sparkContext.broadcast(stopwords_list)\n",
    "\n",
    "print(\"Building the ML Pipeline for classification...\")\n",
    "\n",
    "# 1. Convert category to numeric labels\n",
    "label_indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "\n",
    "# 2. Text preprocessing with optimized tokenizer\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"reviewText\", \n",
    "    outputCol=\"tokens\", \n",
    "    pattern=\"[\\\\s\\\\t\\\\d\\\\(\\\\)\\\\[\\\\]\\\\{\\\\}\\\\.\\\\!\\\\?\\\\,\\\\;\\\\:\\\\+\\\\=\\\\-\\\\_\\\\\\\"\\\\'`\\\\~\\\\#\\\\@\\\\&\\\\*\\\\%\\\\€\\\\$\\\\§\\\\\\\\\\\\/]+\"\n",
    ")\n",
    "\n",
    "# 3. Remove stopwords using broadcast variable\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"tokens\", \n",
    "    outputCol=\"tokens_filtered\", \n",
    "    stopWords=broadcast_stopwords.value\n",
    ")\n",
    "\n",
    "# 4. Create term frequency vectors with limited vocabulary size to reduce dimensionality\n",
    "count_vectorizer = CountVectorizer(\n",
    "    inputCol=\"tokens_filtered\", \n",
    "    outputCol=\"tf\",\n",
    "    vocabSize=20000  # Limit vocabulary size\n",
    ")\n",
    "\n",
    "# 5. Calculate IDF\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tf_idf\")\n",
    "\n",
    "# 6. Feature selection using Chi-Square - reduced dimensionality\n",
    "chi_sq_selector_2000 = ChiSqSelector(\n",
    "    numTopFeatures=2000, \n",
    "    featuresCol=\"tf_idf\", \n",
    "    outputCol=\"selected_features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "chi_sq_selector_500 = ChiSqSelector(\n",
    "    numTopFeatures=500, \n",
    "    featuresCol=\"tf_idf\", \n",
    "    outputCol=\"selected_features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "# 7. Vector normalization\n",
    "normalizer = Normalizer(inputCol=\"selected_features\", outputCol=\"normalized_features\", p=2.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create SVM classifier\n",
    "# Create base binary classifier outside the pipeline definition\n",
    "svm = LinearSVC(featuresCol=\"normalized_features\", labelCol=\"label\")\n",
    "\n",
    "# Wrap in OneVsRest for multi-class classification\n",
    "ovr = OneVsRest(classifier=svm, featuresCol=\"normalized_features\", labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Build the pipeline with 2000 features\n",
    "pipeline_2000 = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    stopwords_remover,\n",
    "    count_vectorizer,\n",
    "    idf,\n",
    "    chi_sq_selector_2000,\n",
    "    normalizer,\n",
    "    ovr\n",
    "])\n",
    "\n",
    "# Build the pipeline with 500 features\n",
    "pipeline_500 = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    stopwords_remover,\n",
    "    count_vectorizer,\n",
    "    idf,\n",
    "    chi_sq_selector_500,\n",
    "    normalizer,\n",
    "    ovr\n",
    "])\n",
    "\n",
    "# Define the SVM parameter grid\n",
    "# Create it once and broadcast to reduce serialization overhead\n",
    "print(\"Setting up parameter grid for SVM optimization...\")\n",
    "# Use getParam instead of direct access to avoid serialization issues\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(svm.maxIter, [10, 50]) \\\n",
    "    .build()\n",
    "\n",
    "# Create an evaluator for model assessment\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Create cross-validators with reduced number of folds to speed up training\n",
    "cv_2000 = CrossValidator(\n",
    "    estimator=pipeline_2000,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,  # Using 3 folds as specified in the original code\n",
    "    parallelism=4,  # Add parallelism to speed up training\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "cv_500 = CrossValidator(\n",
    "    estimator=pipeline_500,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=4,  # Add parallelism to speed up training\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Function to extract parameter settings from a model - optimized version\n",
    "def extract_params(pipeline_model):\n",
    "    for stage in pipeline_model.stages:\n",
    "        if hasattr(stage, 'subModels'):\n",
    "            ovr_model = stage\n",
    "            if hasattr(ovr_model, 'subModels') and len(ovr_model.subModels) > 0:\n",
    "                base_model = ovr_model.subModels[0]\n",
    "                return {\n",
    "                    \"regParam\": base_model.regParam,\n",
    "                    \"standardization\": base_model.standardization,\n",
    "                    \"maxIter\": base_model.maxIter\n",
    "                }\n",
    "    return None\n",
    "\n",
    "# Results container\n",
    "results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c58d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with 2000 features\n",
    "print(\"\\nTraining model with 2000 features...\")\n",
    "print(\"This may take some time...\")\n",
    "cv_model_2000 = cv_2000.fit(train_data)\n",
    "\n",
    "# Get the best model\n",
    "best_model_2000 = cv_model_2000.bestModel\n",
    "params_2000 = extract_params(best_model_2000)\n",
    "\n",
    "# Apply the best model to the test set and cache to improve performance\n",
    "predictions_2000 = best_model_2000.transform(test_data).cache()\n",
    "\n",
    "# Evaluate the model\n",
    "f1_score_2000 = evaluator.evaluate(predictions_2000)\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    \"feature_set\": \"2000 features\",\n",
    "    \"regParam\": params_2000[\"regParam\"],\n",
    "    \"standardization\": params_2000[\"standardization\"],\n",
    "    \"maxIter\": params_2000[\"maxIter\"],\n",
    "    \"f1_score\": f1_score_2000\n",
    "})\n",
    "\n",
    "print(f\"\\nBest parameters for 2000 features:\")\n",
    "print(f\"  regParam: {params_2000['regParam']}\")\n",
    "print(f\"  standardization: {params_2000['standardization']}\")\n",
    "print(f\"  maxIter: {params_2000['maxIter']}\")\n",
    "print(f\"  F1 score on test set: {f1_score_2000:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with 500 features\n",
    "print(\"\\nTraining model with 500 features...\")\n",
    "print(\"This may take some time...\")\n",
    "cv_model_500 = cv_500.fit(train_data)\n",
    "\n",
    "# Get the best model\n",
    "best_model_500 = cv_model_500.bestModel\n",
    "params_500 = extract_params(best_model_500)\n",
    "\n",
    "# Apply the best model to the test set and cache\n",
    "predictions_500 = best_model_500.transform(test_data).cache()\n",
    "\n",
    "# Evaluate the model\n",
    "f1_score_500 = evaluator.evaluate(predictions_500)\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    \"feature_set\": \"500 features\",\n",
    "    \"regParam\": params_500[\"regParam\"],\n",
    "    \"standardization\": params_500[\"standardization\"],\n",
    "    \"maxIter\": params_500[\"maxIter\"],\n",
    "    \"f1_score\": f1_score_500\n",
    "})\n",
    "\n",
    "print(f\"\\nBest parameters for 500 features:\")\n",
    "print(f\"  regParam: {params_500['regParam']}\")\n",
    "print(f\"  standardization: {params_500['standardization']}\")\n",
    "print(f\"  maxIter: {params_500['maxIter']}\")\n",
    "print(f\"  F1 score on test set: {f1_score_500:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which model performed better\n",
    "best_predictions = predictions_2000 if f1_score_2000 > f1_score_500 else predictions_500\n",
    "best_feature_set = \"2000 features\" if f1_score_2000 > f1_score_500 else \"500 features\"\n",
    "\n",
    "# Get label mapping from the indexer - optimize by caching the result\n",
    "label_mapping_model = label_indexer.fit(df)\n",
    "label_mapping = {idx: cat for idx, cat in enumerate(label_mapping_model.labels)}\n",
    "\n",
    "# Convert predictions to a pandas DataFrame - limit columns to only what's needed\n",
    "pred_df = best_predictions.select(\"category\", \"prediction\", \"label\").limit(10000).toPandas()\n",
    "true_labels = pred_df[\"label\"]\n",
    "pred_labels = pred_df[\"prediction\"]\n",
    "\n",
    "# Get top categories efficiently\n",
    "top_categories = category_counts.limit(10).toPandas()['category'].tolist()\n",
    "category_to_idx = {cat: idx for idx, cat in enumerate(label_mapping_model.labels)}\n",
    "top_indices = [category_to_idx[cat] for cat in top_categories]\n",
    "\n",
    "# Initialize confusion matrix\n",
    "conf_matrix = np.zeros((len(top_indices), len(top_indices)), dtype=int)\n",
    "\n",
    "# Fill confusion matrix efficiently\n",
    "for i, true_cat in enumerate(top_indices):\n",
    "    for j, pred_cat in enumerate(top_indices):\n",
    "        conf_matrix[i, j] = sum((true_labels == true_cat) & (pred_labels == pred_cat))\n",
    "\n",
    "# Determine the overall best model configuration\n",
    "best_config = max(results, key=lambda x: x['f1_score'])\n",
    "print(\"\\nBest Overall Configuration:\")\n",
    "print(f\"Feature Set: {best_config['feature_set']}\")\n",
    "print(f\"regParam: {best_config['regParam']}\")\n",
    "print(f\"standardization: {best_config['standardization']}\")\n",
    "print(f\"maxIter: {best_config['maxIter']}\")\n",
    "print(f\"F1 Score: {best_config['f1_score']:.4f}\")\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(\"best_model_params.txt\", \"w\") as f:\n",
    "    f.write(f\"Feature Set: {best_config['feature_set']}\\n\")\n",
    "    f.write(f\"regParam: {best_config['regParam']}\\n\")\n",
    "    f.write(f\"standardization: {best_config['standardization']}\\n\")\n",
    "    f.write(f\"maxIter: {best_config['maxIter']}\\n\")\n",
    "    f.write(f\"F1 Score: {best_config['f1_score']:.4f}\\n\")\n",
    "\n",
    "print(\"\\nBest model parameters saved to 'best_model_params.txt'\")\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"We have successfully implemented an optimized text classification pipeline using Spark ML.\")\n",
    "print(\"The pipeline includes text preprocessing, feature extraction with TF-IDF, and SVM classification.\")\n",
    "print(\"We compared two feature dimensions (2000 vs 500 features) and varied SVM parameters.\")\n",
    "print(f\"The best model achieved an F1 score of {best_config['f1_score']:.4f} on the test set.\")\n",
    "\n",
    "# Clean up and release resources\n",
    "train_data.unpersist()\n",
    "validation_data.unpersist()\n",
    "test_data.unpersist()\n",
    "predictions_2000.unpersist()\n",
    "predictions_500.unpersist()\n",
    "df.unpersist()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped and resources released\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
