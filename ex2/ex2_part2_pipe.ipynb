{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875e7f04-c3e5-44d7-b604-9259bb131bd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# DIC EX2 - part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c9941-f61e-48f4-a5c3-01b2de8d45f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Initialize Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f7029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, StopWordsRemover,\n",
    "    CountVectorizer, IDF, ChiSqSelector, StringIndexer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2590cf54-9939-4f23-be41-abff87d7ce14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/11 21:09:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DIC EX 2 - group 36\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b6529-e715-4393-97be-3f36d9e254cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Set path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efdf2c4c-cd22-429d-9937-5bf54249bc46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DEV_JSON = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"         \n",
    "SAVE_PATH = \"feature_pipe_part2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de0bc7-3f76-48eb-865a-0889b004c1ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402c5577-b0fd-47da-86d8-d87dd13afdde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(DEV_JSON)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a4676-7bde-4402-892d-dbf004e7cba5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Build pipeline\n",
    "\n",
    "### Tokenize using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2597d10b-c173-42b9-af39-3b0a640b0073",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"tokens\", pattern=\"[\\s\\t\\d\\(\\)\\[\\]\\{\\}\\.\\!\\?\\,\\;\\:\\+\\=\\-\\_\\\"\\'`\\~\\#\\@\\&\\*\\%\\€\\$\\§\\\\\\/]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540de42-6fa2-4287-91fc-f2cea5bdaf85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc3f90d-6e83-414a-ab32-bb4c5cbff71e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "def load_stopwords(path= \"stopwords.txt\") -> list[str]:\n",
    "    \"\"\"\n",
    "    Load stopwords from a file efficiently.\n",
    "    \"\"\"\n",
    "    stopwords = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(line.strip() for line in f if line.strip())\n",
    "    return list(stopwords)\n",
    "\n",
    "\n",
    "\n",
    "stopper = StopWordsRemover(\n",
    "    inputCol=\"tokens\", outputCol=\"tokens_filt\",\n",
    "    stopWords=load_stopwords()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb7700-3065-4bc5-bc77-8e26b14ae205",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate token counts and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fefb5d-a405-412a-a01e-114e9a45494c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer\n",
    "\n",
    "tf = CountVectorizer(\n",
    "    inputCol=\"tokens_filt\", outputCol=\"tf\",\n",
    "    vocabSize=20_000, minDF=5\n",
    ")\n",
    "\n",
    "\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tf_idf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375b822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index category\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"category\", outputCol=\"label\", handleInvalid=\"skip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc385e8-e666-42d5-bb04-0478ba481ba0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate chi square values and select top 75 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b77c6d5-b5a3-4172-882b-1fbb11ea3839",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "\n",
    "chisq = ChiSqSelector(\n",
    "    featuresCol=\"tf_idf\", outputCol=\"selected_features\",\n",
    "    labelCol=\"label\",        \n",
    "    numTopFeatures=2_000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868ad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline running\n",
      "Saved model to feature_pipe_part2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "feature_pipe = Pipeline(stages=[\n",
    "    tokenizer, stopper, tf, idf, label_indexer, chisq\n",
    "])\n",
    "\n",
    "print(\"Pipeline running\")\n",
    "feature_model = feature_pipe.fit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a811a80b-e5f2-461b-a2c7-2cc386bd0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "import getpass\n",
    "\n",
    "#safe to hdfs \n",
    "USER = getpass.getuser()                  \n",
    "SAVE_PATH = f\"hdfs:///user/{USER}/models/feature_pipe_part2\"\n",
    "\n",
    "feature_model.write().overwrite().save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51250d-8ccb-4edb-b229-3d894403371d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Get top tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6193ed-fd8c-4685-918d-fe69ebcca7df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/26 22:00:09 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 'author', 'back', 'bad', 'big', 'bit', 'bought', 'buy', 'character', 'characters', 'day', 'easy', 'end', 'enjoyed', 'excellent', 'family', 'feel', 'find', 'fit', 'found', 'give', 'good', 'great', 'happy', 'hard', 'high', 'highly', 'interesting', 'job', 'light', 'long', 'lot', 'love', 'loved', 'made', 'make', 'makes', 'man', 'money', 'music', 'nice', 'part', 'people', 'perfect', 'pretty', 'price', 'problem', 'purchase', 'purchased', 'put', 'quality', 'quot', 'reading', 'real', 'recommend', 'review', 'series', 'set', 'size', 'small', 'sound', 'thing', 'things', 'thought', 'time', 'times', 'wanted', 'watch', 'work', 'works', 'world', 'worth', 'written', 'year', 'years']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "def extract_indices(sparse_vector):\n",
    "    return sparse_vector.indices.tolist()\n",
    "\n",
    "extract_indices_udf = udf(extract_indices, ArrayType(IntegerType()))\n",
    "\n",
    "df_with_indices = result.withColumn(\"indices\", extract_indices_udf(result[\"selectedFeatures\"]))\n",
    "indices = df_with_indices.select(\"indices\").rdd.flatMap(lambda row: row.indices).distinct().collect()\n",
    "\n",
    "vocab = countModel.vocabulary\n",
    "words = [vocab[index] for index in indices]\n",
    "print(sorted(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4eae1-a351-4faa-8a88-76c28e2db169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Write tokens to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c07d98-482c-4a8d-ab97-6ddc69084795",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\" \".join(sorted(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df8e79-3270-4063-b293-f1f55891c3b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
