{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875e7f04-c3e5-44d7-b604-9259bb131bd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# DIC EX2 - part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c9941-f61e-48f4-a5c3-01b2de8d45f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Initialize Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f7029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, StopWordsRemover,\n",
    "    CountVectorizer, IDF, ChiSqSelector, StringIndexer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2590cf54-9939-4f23-be41-abff87d7ce14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DIC EX 2 - group 36\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b6529-e715-4393-97be-3f36d9e254cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Set path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efdf2c4c-cd22-429d-9937-5bf54249bc46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DEV_JSON = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"         \n",
    "SAVE_PATH = \"feature_pipe_part2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de0bc7-3f76-48eb-865a-0889b004c1ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "402c5577-b0fd-47da-86d8-d87dd13afdde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"reviews_devset.json\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a4676-7bde-4402-892d-dbf004e7cba5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Build pipeline\n",
    "\n",
    "### Tokenize using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2597d10b-c173-42b9-af39-3b0a640b0073",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\timgr\\AppData\\Local\\Temp\\ipykernel_32304\\3300093208.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"tokens\", pattern=\"[\\s\\t\\d\\(\\)\\[\\]\\{\\}\\.\\!\\?\\,\\;\\:\\+\\=\\-\\_\\\"\\'`\\~\\#\\@\\&\\*\\%\\€\\$\\§\\\\\\/]+\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"tokens\", pattern=\"[\\s\\t\\d\\(\\)\\[\\]\\{\\}\\.\\!\\?\\,\\;\\:\\+\\=\\-\\_\\\"\\'`\\~\\#\\@\\&\\*\\%\\€\\$\\§\\\\\\/]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540de42-6fa2-4287-91fc-f2cea5bdaf85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dc3f90d-6e83-414a-ab32-bb4c5cbff71e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "def load_stopwords(path= \"stopwords.txt\") -> list[str]:\n",
    "    \"\"\"\n",
    "    Load stopwords from a file efficiently.\n",
    "    \"\"\"\n",
    "    stopwords = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(line.strip() for line in f if line.strip())\n",
    "    return list(stopwords)\n",
    "\n",
    "\n",
    "\n",
    "stopper = StopWordsRemover(\n",
    "    inputCol=\"tokens\", outputCol=\"tokens_filt\",\n",
    "    stopWords=load_stopwords()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb7700-3065-4bc5-bc77-8e26b14ae205",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate token counts and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0fefb5d-a405-412a-a01e-114e9a45494c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer\n",
    "\n",
    "tf = CountVectorizer(\n",
    "    inputCol=\"tokens_filt\", outputCol=\"tf\",\n",
    "    vocabSize=20_000, minDF=5\n",
    ")\n",
    "\n",
    "\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tf_idf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "375b822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index category\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"category\", outputCol=\"label\", handleInvalid=\"skip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc385e8-e666-42d5-bb04-0478ba481ba0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate chi square values and select top 75 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b77c6d5-b5a3-4172-882b-1fbb11ea3839",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "\n",
    "chisq = ChiSqSelector(\n",
    "    featuresCol=\"tf_idf\", outputCol=\"selected_features\",\n",
    "    labelCol=\"label\",        \n",
    "    numTopFeatures=2_000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "868ad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline running\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "feature_pipe = Pipeline(stages=[\n",
    "    tokenizer, stopper, tf, idf, label_indexer, chisq\n",
    "])\n",
    "\n",
    "print(\"Pipeline running\")\n",
    "feature_model = feature_pipe.fit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a811a80b-e5f2-461b-a2c7-2cc386bd0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "import getpass\n",
    "\n",
    "#safe to hdfs \n",
    "USER = getpass.getuser()                  \n",
    "SAVE_PATH = f\"hdfs:///user/{USER}/models/feature_pipe_part2\"\n",
    "\n",
    "feature_model.write().overwrite().save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51250d-8ccb-4edb-b229-3d894403371d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Get top tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8364ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizerModel, ChiSqSelectorModel\n",
    "\n",
    "cv_model = next(\n",
    "    s for s in feature_model.stages\n",
    "    if isinstance(s, CountVectorizerModel)\n",
    ")\n",
    "vocab = cv_model.vocabulary\n",
    "\n",
    "sel_model = next(s for s in feature_model.stages\n",
    "                 if isinstance(s, ChiSqSelectorModel))\n",
    "all_selected = sel_model.selectedFeatures    \n",
    "\n",
    "\n",
    "top75_tokens = [vocab[i] for i in all_selected]\n",
    "\n",
    "with open(\"output_ds.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(top75_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6193ed-fd8c-4685-918d-fe69ebcca7df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/26 22:00:09 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 'author', 'back', 'bad', 'big', 'bit', 'bought', 'buy', 'character', 'characters', 'day', 'easy', 'end', 'enjoyed', 'excellent', 'family', 'feel', 'find', 'fit', 'found', 'give', 'good', 'great', 'happy', 'hard', 'high', 'highly', 'interesting', 'job', 'light', 'long', 'lot', 'love', 'loved', 'made', 'make', 'makes', 'man', 'money', 'music', 'nice', 'part', 'people', 'perfect', 'pretty', 'price', 'problem', 'purchase', 'purchased', 'put', 'quality', 'quot', 'reading', 'real', 'recommend', 'review', 'series', 'set', 'size', 'small', 'sound', 'thing', 'things', 'thought', 'time', 'times', 'wanted', 'watch', 'work', 'works', 'world', 'worth', 'written', 'year', 'years']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52f4eae1-a351-4faa-8a88-76c28e2db169",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Write tokens to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c07d98-482c-4a8d-ab97-6ddc69084795",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\" \".join(sorted(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df8e79-3270-4063-b293-f1f55891c3b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
